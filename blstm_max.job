#!/bin/bash

#SBATCH --partition=gpu_shared
#SBATCH --gres=gpu:1
#SBATCH --job-name=blstm_max
#SBATCH --cpus-per-task=3
#SBATCH --time=15:00:00
#SBATCH --mem=32000M
#SBATCH --output=slurm_output_%A.out

module purge
module load 2019
module load Python/3.7.5-foss-2019b
module load CUDA/10.1.243
module load cuDNN/7.6.5.32-CUDA-10.1.243
module load NCCL/2.5.6-CUDA-10.1.243
module load Anaconda3/2018.12

# Your job starts in the directory where you call sbatch
cd $HOME/Sentence_Representations_from_NLI
# Activate your environment
source activate dl2020
# Run your code
echo "running BLSTM_max"
srun python -u train.py --debug False --glove_name 840B --epochs 30 --batch_size 64 --encoder_type BLSTM_Encoder --lstm_num_hidden 2048 --max_pooling True

echo "finish"